{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "------------\n",
        "### A01378965 - Emilio Rios Ochoa\n",
        "### A01379868 - Jared Abraham Flores Guarneros"
      ],
      "metadata": {
        "id": "Y2m8ElT-xOHb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAb0XHn9U19Y"
      },
      "source": [
        "# Naive Bayes method\n",
        "##*(Reference Only)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WosT_tFqTDvx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WABagzkoTH8f"
      },
      "outputs": [],
      "source": [
        "# Read Dataset and save it into a Dataframe\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiX1DzWNTTMp"
      },
      "outputs": [],
      "source": [
        "# Percentage of the dataset to be used as part of the testing\n",
        "test_group = 0.5\n",
        "# Split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"review\"], df[\"sentiment\"], test_size=test_group, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK-ywR5kIOv4"
      },
      "outputs": [],
      "source": [
        "# Defines a pipeline to make sure the classification is done after the vectorization\n",
        "model = Pipeline([\n",
        "    # Vectorizes the data to be managed as numbers instead of text\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    # Applies a Multinomial Naive Bayes\n",
        "    ('classifier', MultinomialNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoloUsEEIStz"
      },
      "outputs": [],
      "source": [
        "# Trains the model using the training sets\n",
        "model.fit(X_train, y_train)\n",
        "# The model is tested to validate its accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "# The accuracy and other metrics are reported to evaluate its performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwzRACjkSpq_",
        "outputId": "6f6fed36-210b-464d-ebeb-b6d5ca0f29d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.75%\n",
            "Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.87      0.85     12483\n",
            "    positive       0.87      0.82      0.84     12517\n",
            "\n",
            "    accuracy                           0.85     25000\n",
            "   macro avg       0.85      0.85      0.85     25000\n",
            "weighted avg       0.85      0.85      0.85     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Displays the results\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "print(\"Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FliY1c1GTi0P",
        "outputId": "e1974bd6-d8e0-4cc4-d174-ac55ab8c8426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New review test: ['It was really awful mate', 'A bit slow, I loved it though', 'I hated it, the actors were as bad as my back pain']\n",
            "Test prediction: ['negative' 'positive' 'negative']\n"
          ]
        }
      ],
      "source": [
        "# Executes a few more tests (not seen in the dataset) to evaluate the prediction's accuracy\n",
        "new_comments = [\"It was really awful mate\", \"A bit slow, I loved it though\", \"I hated it, the actors were as bad as my back pain\"]\n",
        "new_pred = model.predict(new_comments)\n",
        "\n",
        "print(\"New review test:\", new_comments)\n",
        "print(\"Test prediction:\", new_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUMPkkg0yzG7"
      },
      "source": [
        "# SVM Method"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For source data manipulation\n",
        "import pandas as pd\n",
        "# For regex manipulation in data cleaning\n",
        "import re\n",
        "# For plotting the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "# For model construction\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "# NLTK for language manipulation\n",
        "from nltk import download as nltk_download\n",
        "nltk_download(\"stopwords\")\n",
        "nltk_download(\"punkt\")\n",
        "nltk_download(\"wordnet\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "XrCXAXPByB7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Dataset and save it into a Dataframe\n",
        "df = pd.read_csv(\"IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "d3cG2pDJyWFO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to remove any unnecessary information from each comment\n",
        "def clean_text(text):\n",
        "    # Define lists of elements to be modified or removed\n",
        "    conditional_words = [\"unless\", \"if\", \"until\", \"except\"]\n",
        "    unwanted_html_tags = [\"<.*?>\"]\n",
        "    # Remove unwanted HTML tags (Replace with nothing)\n",
        "    for tag in unwanted_html_tags:\n",
        "        text = re.sub(tag, \"\", text)\n",
        "    # Replace anything that is not a letter (nubmers, apostrophes, etc.) with an space\n",
        "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "    text = text.lower()\n",
        "    # Tokenize text (Split sentences into words)\n",
        "    tokens = word_tokenize(text)\n",
        "    # Replace conditional statements with negation words\n",
        "    filtered_tokens = [token if token not in conditional_words else \"not\" for token in tokens]\n",
        "    # Remove stop words (such as the, for, etc.)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_tokens = [token for token in filtered_tokens if token not in stop_words]\n",
        "    # Lemmatize tokens (consider similar words as just one)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "    # Create a new cleaned comment/review string \n",
        "    return \" \".join(lemmatized_tokens)\n"
      ],
      "metadata": {
        "id": "PMEhOH_u3g3E"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into the text and labels for training\n",
        "X = df[\"review\"]\n",
        "y = df[\"sentiment\"]\n",
        "\n",
        "# Display the original text before cleaning\n",
        "print(\"=====> BEFORE CLEANING:\")\n",
        "print(X)\n",
        "\n",
        "# Iterate to clean all comments in the source dataframe\n",
        "for i in range(len(df)):\n",
        "    original_text = df.loc[i, \"review\"]\n",
        "    cleaned_text = clean_text(original_text)\n",
        "    df.loc[i, \"review\"] = cleaned_text\n",
        "\n",
        "# \"Reloads\" the review column since it was modified during the cleaning\n",
        "X = df[\"review\"]\n",
        "# Display the text after cleaning\n",
        "print(\"=====> AFTER CLEANING:\")\n",
        "print(X)\n"
      ],
      "metadata": {
        "id": "fa4bEUMOzh8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text data to numerical values to be interpreted by the model\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "p0HtUz5Z3c5Z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percentage of the dataset to be used as part of the testing\n",
        "test_group = 0.25\n",
        "# Split the data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_group, random_state=42)"
      ],
      "metadata": {
        "id": "UoQLU2Uizli0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the model using a linear kernel and trains it\n",
        "svm = LinearSVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# The model is tested to validate its accuracy\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "# The accuracy and other metrics are reported to evaluate its performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Wv2XEULmzrxS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays the results\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "print(\"Report:\\n\", report)"
      ],
      "metadata": {
        "id": "01yxp6J7zv_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghXqcpcD3VIn"
      },
      "outputs": [],
      "source": [
        "# Executes a few more tests (not seen in the dataset) to evaluate the prediction's accuracy\n",
        "new_comments = [\"It was really awful mate\", \"A bit slow, I loved it though\", \"I hated it, the actors were as bad as my back pain\"]\n",
        "new_pred = svm.predict(vectorizer.transform(new_comments))\n",
        "\n",
        "print(\"New review test:\", new_comments)\n",
        "print(\"Test prediction:\", new_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates a confusion matrix graph to have a visual on the model's performance\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cm_graph = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Negative\", \"Positive\"])\n",
        "cm_graph.plot(colorbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rsVEhamoCWuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RAb0XHn9U19Y"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}